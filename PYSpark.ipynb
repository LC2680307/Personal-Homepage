{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import findspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SQLContext, SparkContext\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\sql\\context.py:114: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "sparkc = SparkContext('local')\n",
    "sqlc = SQLContext(sparkc)\n",
    "train_data = sqlc.read.csv('./train.csv', sep='\\t', header=True)\n",
    "test_data = sqlc.read.csv('./test.csv', sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless columns \n",
    "to_drop = ['Row','Step Start time','First Transaction Time','Correct Transaction Time','Step End Time',\n",
    "           'Step Duration (sec)','Correct Step Duration (sec)','Error Step Duration (sec)','Incorrects','Hints','Corrects']\n",
    "train_data = train_data.drop(*to_drop)\n",
    "test_data = test_data.drop(*to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_unit(str): \n",
    "    return str.split(',')[0]\n",
    "    \n",
    "def set_section(str):\n",
    "    return str.split(',')[1]\n",
    "ph = 'Problem Hierarchy'\n",
    "udfset_unit = F.udf(set_unit, StringType())\n",
    "udfset_section = F.udf(set_section, StringType())\n",
    "test_data = test_data.withColumn('Problem Unit', udfset_unit(ph))\n",
    "test_data = test_data.withColumn('Problem Section', udfset_section(ph))\n",
    "test_data = test_data.drop(ph)\n",
    "train_data = train_data.withColumn('Problem Unit', udfset_unit(ph))\n",
    "train_data = train_data.withColumn('Problem Section', udfset_section(ph))\n",
    "train_data =train_data.drop(ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode\n",
    "def change_code(a):\n",
    "    dict_1 = {}\n",
    "    li = []\n",
    "    flag = 1\n",
    "    global train_data,test_data\n",
    "    tran = train_data.union(test_data)\n",
    "    temp = tran.select(a).distinct().collect()\n",
    "    for i in temp:\n",
    "        li.append(i[a])\n",
    "    for i in li:\n",
    "        dict_1[i] = flag\n",
    "        flag += 1\n",
    "    def code1(str):\n",
    "        return dict_1[str]\n",
    "     \n",
    "    udfcode = F.udf(code1,IntegerType())\n",
    "    new_a  = 'New '+a\n",
    "    test_data = test_data.withColumn(new_a, udfcode(a))\n",
    "    test_data = test_data.drop(a)\n",
    "    test_data = test_data.withColumnRenamed(new_a, a)\n",
    "    train_data = train_data.withColumn(new_a, udfcode(a))\n",
    "    train_data = train_data.drop(a)\n",
    "    train_data = train_data.withColumnRenamed(new_a, a)\n",
    "new_code = ['Anon Student Id','Problem Name','Problem Unit','Problem Section','Step Name']\n",
    "new_code_length = len(new_code)\n",
    "for i in range(0,new_code_length):\n",
    "    change_code(new_code[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate\n",
    "def KC(str):\n",
    "    if not str:\n",
    "        return 0\n",
    "    else:\n",
    "        count = str.count('~~')\n",
    "        return count+1\n",
    "\n",
    "def Opp(str):\n",
    "    if not str:\n",
    "        return 0.0\n",
    "    else:\n",
    "        sum = 0\n",
    "        count = 0\n",
    "        li = str.split('~~')\n",
    "        for i in li:\n",
    "            sum += eval(i)\n",
    "            count += 1\n",
    "        float1 = float(sum/count)\n",
    "        return float1\n",
    "\n",
    "udf_KC = F.udf(KC, IntegerType())\n",
    "udf_Opp = F.udf(Opp, FloatType())\n",
    "o_d = 'Opportunity(Default)'\n",
    "k_c = 'KC Count'\n",
    "o_a  = 'Opportunity Average'\n",
    "train_data = train_data.withColumn(k_c, udf_KC('KC(Default)'))\n",
    "train_data = train_data.withColumn(o_a , udf_Opp(o_d))\n",
    "train_data = train_data.drop(o_d)\n",
    "test_data = test_data.withColumn(k_c , udf_KC('KC(Default)'))\n",
    "test_data = test_data.withColumn(o_a , udf_Opp(o_d))\n",
    "test_data = test_data.drop(o_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling\n",
    "mark_data = train_data.filter(train_data['Correct First Attempt'] == '1')\n",
    "CT = 'count'\n",
    "\n",
    "def Personal_Count():\n",
    "    global train_data,test_data\n",
    "    d1 = {}\n",
    "    s = 0\n",
    "    ASI = 'Anon Student Id'\n",
    "    new_train = train_data.groupBy(ASI).count().collect()\n",
    "    new_mark = mark_data.groupBy(ASI).count().collect()\n",
    "    for i in new_train:\n",
    "        if i[ASI] not in d1:\n",
    "            d1[i[ASI]] = 0\n",
    "    for i in new_mark:\n",
    "        d1[i[ASI]] = i[CT]\n",
    "   \n",
    "    \n",
    "    for i in d1.keys():\n",
    "        s = s + d1[i]\n",
    "    mean = s/len(new_train)\n",
    "    float_mean = float(mean)\n",
    "    \n",
    "    def Id_Count(id):\n",
    "        if id in d1.keys():\n",
    "            id_d = d1[id]\n",
    "            return float(id_d)\n",
    "        else:\n",
    "            return float_mean\n",
    "        \n",
    "    udf_Id_Count = F.udf(Id_Count, FloatType())\n",
    "    train_data = train_data.withColumn('Personal CFAC', udf_Id_Count(ASI))\n",
    "    test_data = test_data.withColumn('Personal CFAC',udf_Id_Count(ASI))\n",
    "\n",
    "Personal_Count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Personal_Rate():\n",
    "    global train_data,test_data\n",
    "    d = {}\n",
    "    d1 = {}\n",
    "    d2 = {} \n",
    "    s = 0\n",
    "    ASI = 'Anon Student Id'\n",
    "    new_mark = mark_data.groupBy(ASI).count().collect()\n",
    "    new_train = train_data.groupBy(ASI).count().collect()\n",
    "    for i in new_mark:\n",
    "        d1[i[ASI]] = i[CT]\n",
    "    for i in new_train:\n",
    "        d2[i[ASI]] = i[CT]\n",
    "    for i in new_mark:\n",
    "        d[i[ASI]] = i[CT]/d2[i[ASI]]\n",
    "    for i in new_train:\n",
    "        if i[ASI] not in d:\n",
    "            d[i[ASI]] = 0\n",
    "   \n",
    "    for i in d.keys():\n",
    "        s = s + d[i]\n",
    "    mean = s/len(new_train)\n",
    "    float_mean = float(mean)\n",
    "    def Id_Rate(id):\n",
    "        if id in d.keys():\n",
    "            id_d = d[id]\n",
    "            return float(id_d)\n",
    "        else:\n",
    "            return float_mean\n",
    "        \n",
    "    udf_Id_Rate = F.udf(Id_Rate, FloatType())\n",
    "    train_data = train_data.withColumn('Personal CFAR', udf_Id_Rate(ASI))\n",
    "    test_data = test_data.withColumn('Personal CFAR',udf_Id_Rate(ASI))\n",
    "\n",
    "Personal_Rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Problem_Rate():\n",
    "    global train_data,test_data\n",
    "    d = {}\n",
    "    d1 = {}\n",
    "    d2 = {} \n",
    "    s = 0\n",
    "    PN = 'Problem Name'\n",
    "    new_mark = mark_data.groupBy(PN).count().collect()\n",
    "    new_train = train_data.groupBy(PN).count().collect()\n",
    "    for i in new_mark:\n",
    "        d1[i[PN]] = i[CT]\n",
    "    for i in new_train:\n",
    "        d2[i[PN]] = i[CT]\n",
    "    for i in new_mark:\n",
    "        d[i[PN]] = i[CT]/d2[i[PN]]\n",
    "    for i in new_train:\n",
    "        if i[PN] not in d:\n",
    "            d[i[PN]] = 0\n",
    "    \n",
    "    for i in d.keys():\n",
    "        s = s + d[i]\n",
    "    mean = s/len(new_train)\n",
    "    float_mean = float(mean)\n",
    "    def Name_Rate(id):\n",
    "        if id in d.keys():\n",
    "            id_d = d[id]\n",
    "            return float(id_d)\n",
    "        else:\n",
    "            return float_mean\n",
    "        \n",
    "\n",
    "    udf_Name_Rate = F.udf(Name_Rate, FloatType())\n",
    "    train_data = train_data.withColumn('Problem CFAR', udf_Name_Rate(PN))\n",
    "    test_data = test_data.withColumn('Problem CFAR',udf_Name_Rate(PN))\n",
    "\n",
    "Problem_Rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unit_Rate():\n",
    "    global train_data,test_data\n",
    "    d = {}\n",
    "    d1 = {}\n",
    "    d2 = {} \n",
    "    s = 0\n",
    "    PU = 'Problem Unit'\n",
    "    new_mark = mark_data.groupBy(PU).count().collect()\n",
    "    new_train = train_data.groupBy(PU).count().collect()\n",
    "    for i in new_mark:\n",
    "        d1[i[PU]] = i[CT]\n",
    "    for i in new_train:\n",
    "        d2[i[PU]] = i[CT]\n",
    "    for i in new_mark:\n",
    "        d[i[PU]] = i[CT]/d2[i[PU]]\n",
    "    for i in new_train:\n",
    "        if i[PU] not in d:\n",
    "            d[i[PU]] = 0\n",
    "    for i in d.keys():\n",
    "        s = s + d[i]\n",
    "    mean = s/len(new_train)\n",
    "    float_mean = float(mean)\n",
    "    def Unitid_Rate(id):\n",
    "        if id in d.keys():\n",
    "            id_d = d[id]\n",
    "            return float(id_d)\n",
    "        else:\n",
    "            return float_mean\n",
    "        \n",
    "    udf_Unitid_Rate = F.udf(Unitid_Rate, FloatType())\n",
    "    train_data = train_data.withColumn('Unit CFAR', udf_Unitid_Rate(PU))\n",
    "    test_data = test_data.withColumn('Unit CFAR',udf_Unitid_Rate(PU))\n",
    "\n",
    "Unit_Rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Section_Rate():\n",
    "    global train_data,test_data\n",
    "    d = {}\n",
    "    d1 = {}\n",
    "    d2 = {} \n",
    "    s = 0\n",
    "    PS = 'Problem Section'\n",
    "    new_mark = mark_data.groupBy(PS).count().collect()\n",
    "    new_train = train_data.groupBy(PS).count().collect()\n",
    "    for i in new_mark:\n",
    "        d1[i[PS]] = i[CT]\n",
    "    for i in new_train:\n",
    "        d2[i[PS]] = i[CT]\n",
    "    for i in new_mark:\n",
    "        d[i[PS]] = i[CT]/d2[i[PS]]\n",
    "    for i in new_train:\n",
    "        if i[PS] not in d:\n",
    "            d[i[PS]] = 0\n",
    "    for i in d.keys():\n",
    "        s = s + d[i]\n",
    "    mean = s/len(new_train)\n",
    "    float_mean = float(mean)\n",
    "    def Sectionid_Rate(id):\n",
    "        if id in d.keys():\n",
    "            id_d = d[id]\n",
    "            return float(id_d)\n",
    "        else:\n",
    "            return float_mean\n",
    "        \n",
    "    udf_Sectionid_Rate = F.udf(Sectionid_Rate, FloatType())\n",
    "    train_data= train_data.withColumn('Section CFAR', udf_Sectionid_Rate(PS))\n",
    "    test_data = test_data.withColumn('Section CFAR',udf_Sectionid_Rate(PS))\n",
    "    \n",
    "\n",
    "Section_Rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Step_Rate():\n",
    "    global train_data,test_data\n",
    "    d = {}\n",
    "    d1 = {}\n",
    "    d2 = {} \n",
    "    s = 0\n",
    "    SN = 'Step Name'\n",
    "    new_mark = mark_data.groupBy(SN).count().collect()\n",
    "    new_train = train_data.groupBy(SN).count().collect()\n",
    "    for i in new_mark:\n",
    "        d1[i[SN]] = i[CT]\n",
    "    for i in new_train:\n",
    "        d2[i[SN]] = i[CT]\n",
    "    for i in new_mark:\n",
    "        d[i[SN]] = i[CT]/d2[i[SN]]\n",
    "    for i in new_train:\n",
    "        if i[SN] not in d:\n",
    "            d[i[SN]] = 0\n",
    "    for i in d.keys():\n",
    "        s = s + d[i]\n",
    "    mean = s/len(new_train)\n",
    "    float_mean = float(mean)\n",
    "\n",
    "    def Name_Rate(id):\n",
    "        if id in d.keys():\n",
    "            id_d = d[id]\n",
    "            return float(id_d)\n",
    "        else:\n",
    "            return float_mean\n",
    "        \n",
    "    udf_Name_Rate = F.udf(Name_Rate, FloatType())\n",
    "    train_data = train_data.withColumn('Step CFAR', udf_Name_Rate(SN))\n",
    "    test_data = test_data.withColumn('Step CFAR',udf_Name_Rate(SN))\n",
    "\n",
    "Step_Rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KC_Rate():\n",
    "    global train_data,test_data\n",
    "    d = {}\n",
    "    d1 = {}\n",
    "    d2 = {} \n",
    "    s = 0\n",
    "    KC = 'KC(Default)'\n",
    "    new_mark = mark_data.groupBy(KC).count().collect()\n",
    "    new_train = train_data.groupBy(KC).count().collect()\n",
    "    for i in new_mark:\n",
    "        d1[i[KC]] = i[CT]\n",
    "    for i in new_train:\n",
    "        d2[i[KC]] = i[CT]\n",
    "    for i in new_mark:\n",
    "        d[i[KC]] = i[CT]/d2[i[KC]]\n",
    "    for i in new_train:\n",
    "        if i[KC] not in d:\n",
    "            d[i[KC]] = 0\n",
    "    for i in d.keys():\n",
    "        s = s + d[i]\n",
    "    mean = s/len(new_train)\n",
    "    float_mean = float(mean)\n",
    "\n",
    "    def KCid_Rate(id):\n",
    "        if id in d.keys():\n",
    "            id_d = d[id]\n",
    "            return float(id_d)\n",
    "        else:\n",
    "            return float_mean\n",
    "        \n",
    "    udf_KCid_Rate = F.udf(KCid_Rate, FloatType())\n",
    "    train_data = train_data.withColumn('KC CFAR', udf_KCid_Rate(KC))\n",
    "    test_data = test_data.withColumn('KC CFAR',udf_KCid_Rate(KC))\n",
    "\n",
    "KC_Rate()\n",
    "train_data = train_data.drop('KC(Default)')\n",
    "test_data = test_data.drop('KC(Default)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = train_data.toPandas()\n",
    "test_pd = test_data.toPandas()\n",
    "train_pd.to_csv('./train_pyspark_data.csv', sep='\\t')\n",
    "test_pd.to_csv('./test_pyspark_data.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
